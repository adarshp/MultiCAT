{% extends "base.html" %}

{% block title %}
    {{ metadata.title or "Datasette" }}: {% for database in databases %}{{ database.name }}{% if not loop.last %}, {% endif %}{% endfor %}
{% endblock %}

{% block body_class %}index{% endblock %}

{% block content %}
<h1>{{ metadata.title or "Datasette" }}{% if private %} ðŸ”’{% endif %}</h1>
{{ render_markdown("""

Welcome to the web UI for the MultiCAT dataset! We provide here a web UI for
exploring the dataset, as well as links to papers and systems that use this
dataset.


## Abstract

Successful teamwork requires team members to understand each other and
communicate effectively, managing multiple linguisticand paralinguistic tasks at
once. Because of the potential for interrelatedness of these tasks, it is
important to have the ability to make multiple types of predictions on the same
dataset. Here, we introduce Multimodal Communication Annotations for Teams
(MultiCAT), a speech- and text-based dataset consisting of audio recordings,
automated and hand-corrected transcriptions. MultiCAT builds upon data from
teams working collaboratively to save victims in a simulated search and rescue
mission, and consists of annotations and benchmark results for the following
tasks: (1) dialog act classification, (2) adjacency pair detection, (3)
sentiment and emotion recognition, (4) closed-loop communication detection, and
(5) vocal (phonetic) entrainment detection. We also present exploratory analyses
on the relationship between our annotations and team outcomes. We posit that
additional work on these tasks and their intersection will further improve
understanding of team communication and its relation to team performance. 

## Paper and code

- The PDF of our NAACL 2025 Findings paper and code for the benchmark analyses
  (and this web UI) can be found here: https://github.com/adarshp/MultiCAT.
- When exploring the different tables, metadata describing the columns will be
  displayed at the top of the page. The metadata is loaded from the file
  `datasette_interface/metadata.yml` in the Github repository.

## Exploring the data

The dataset is served via a [single SQLite database](/multicat).

An entity relationship diagram representing the database schema is
available here: [ERD diagram](/assets/db_diagram.png).

Feel free to try different SQL queries, use the
programmatic APIs provided by Datasette, or simply [download the whole SQLite
database](https://multicat.lab.pyarelal.xyz/multicat.db).

## Citation

If you use this dataset, please cite our [NAACL 2025 Findings
paper](https://openreview.net/forum?id=nkxpva8fN5) that introduces the dataset.

We will replace the metadata of the citations below with the ones from the
official ACL Anthology entry when it is published.

### BibTeX Format

""") }}

<div class="code">
    <pre>
    <code>
@inproceedings{
    multicat,
    title={Multi{CAT}: Multimodal Communication Annotations for Teams},
    author = {Adarsh Pyarelal
          and John Culnan
          and Ayesha Qamar
          and Meghavarshini Krishnaswamy
          and Yuwei Wang
          and Chen Chen
          and Md Messal Monem Miah
          and Shahriar Hormozi
          and Jonathan Tong
          and Ruihong Huang
    },
    booktitle={NAACL 2025 Findings},
    year={2025},
    url={https://openreview.net/forum?id=nkxpva8fN5}
}
    </code>
    </pre>
</div>

{{ render_markdown("""

### APA Format

Adarsh Pyarelal, John Culnan, Ayesha Qamar, Meghavarshini Krishnaswamy, Yuwei
Wang, Chen Chen, Md Messal Monem Miah, Shahriar Hormozi, Jonathan Tong & Ruihong
Huang (2025). MultiCAT: Multimodal Communication Annotations for Teams. In NAACL
2025 Findings.


""") }}
            {% for database in databases %}
                <h2 style="padding-left: 10px; border-left: 10px solid #{{ database.color }}">
                    <a href="{{ urls.database(database.name) }}">{{ database.name }}</a>
                    {% if database.private %} ðŸ”’{% endif %}
                </h2>
                <p>
                    {% if database.show_table_row_counts %}{{ "{:,}".format(database.table_rows_sum) }} rows in {% endif %}{{ database.tables_count }} table{% if database.tables_count != 1 %}s{% endif %}{% if database.tables_count and database.hidden_tables_count %}, {% endif -%}
                    {% if database.hidden_tables_count -%}
                        {% if database.show_table_row_counts %}{{ "{:,}".format(database.hidden_table_rows_sum) }} rows in {% endif %}{{ database.hidden_tables_count }} hidden table{% if database.hidden_tables_count != 1 %}s{% endif -%}
                    {% endif -%}
                    {% if database.views_count -%}
                        {% if database.tables_count or database.hidden_tables_count %}, {% endif -%}
                        {{ "{:,}".format(database.views_count) }} view{% if database.views_count != 1 %}s{% endif %}
                    {% endif %}
                </p>
                <p>{% for table in database.tables_and_views_truncated %}<a href="{{ urls.table(database.name, table.name) }}"{% if table.count %} title="{{ table.count }} rows"{% endif %}>{{ table.name }}</a>{% if table.private %} ðŸ”’{% endif %}{% if not loop.last %}, {% endif %}{% endfor %}{% if database.tables_and_views_more %}, <a href="{{ urls.database(database.name) }}">...</a>{% endif %}</p>
            {% endfor %}

{{ render_markdown("""
## Funding Acknowledgment

- The creation of this dataset was funded by the Army Research Office and was
accomplished under Grant Number W911NF-20-1-0002. The grant was awarded through
the Defense Advanced Research Projects Agency (DARPA).
- Continued support (documentation updates, replying to questions from dataset
users, etc.) is supported by Army Research Office (ARO) Award Number
W911NF-24-2-0034.
""") }}
{% endblock %}
